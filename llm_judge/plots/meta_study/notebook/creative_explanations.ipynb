{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "processed_dir = get_working_dir() / 'data' / 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv')"
   ],
   "id": "4e0b4b04352e76e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "processed_dir = get_working_dir() / 'data' / 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Create plots/demographics directory\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ],
   "id": "bc582edcd4762bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T16:57:10.343585Z",
     "start_time": "2025-03-15T16:57:10.256943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Define output directory and create it if needed.\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load the CSV file.\n",
    "df = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv')\n",
    "\n",
    "# Debug: print value counts of the original column.\n",
    "print(\"Original value counts for 'creative_explanations_likeability':\")\n",
    "print(df['creative_explanations_likeability'].value_counts(), \"\\n\")\n",
    "\n",
    "# If the column is object type, map the responses to numeric values.\n",
    "if df['creative_explanations_likeability'].dtype == object:\n",
    "    likeability_mapping = {\n",
    "        \"Strongly dislike\": 1,\n",
    "        \"Somewhat dislike\": 2,\n",
    "        \"Neither like nor dislike\": 3,\n",
    "        \"Somewhat like\": 4,\n",
    "        \"Strongly like\": 5\n",
    "    }\n",
    "    df['creative_explanations_likeability_numeric'] = df['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "else:\n",
    "    df['creative_explanations_likeability_numeric'] = pd.to_numeric(df['creative_explanations_likeability'], errors='coerce')\n",
    "\n",
    "# Debug: print value counts of the numeric column.\n",
    "print(\"Value counts for 'creative_explanations_likeability_numeric':\")\n",
    "print(df['creative_explanations_likeability_numeric'].value_counts(), \"\\n\")\n",
    "\n",
    "# Define bin edges such that each rating 1â€“5 falls into its own bin.\n",
    "bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(df['creative_explanations_likeability_numeric'].dropna(), bins=bins, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Creative Explanations Likeability')\n",
    "plt.xlabel('Likeability Rating')\n",
    "plt.ylabel('Count')\n",
    "# Set x-ticks at the center of each bin: 1,2,3,4,5.\n",
    "tick_positions = [1, 2, 3, 4, 5]\n",
    "tick_labels = [\"Strongly dislike\", \"Somewhat dislike\", \"Neither like nor dislike\", \"Somewhat like\", \"Strongly like\"]\n",
    "plt.xticks(tick_positions, tick_labels, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'creative_explanations_likeability.png')\n",
    "plt.close()\n"
   ],
   "id": "542ebcf258645337",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value counts for 'creative_explanations_likeability':\n",
      "creative_explanations_likeability\n",
      "Somewhat like               32\n",
      "Strongly like               23\n",
      "Neither like nor dislike    21\n",
      "Somewhat dislike            13\n",
      "Strongly dislike            12\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for 'creative_explanations_likeability_numeric':\n",
      "creative_explanations_likeability_numeric\n",
      "4    32\n",
      "5    23\n",
      "3    21\n",
      "2    13\n",
      "1    12\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between CE likeability and age group",
   "id": "bb39e8752002fdec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:00:27.990769Z",
     "start_time": "2025-03-15T17:00:27.959402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Define output directory (if you wish to save any plots later)\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load the creative preferences file.\n",
    "df_creative = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv')\n",
    "\n",
    "# Load the demographics file (for creative preferences, we assume it's m_demographics.csv).\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv')\n",
    "\n",
    "# Merge the two files on prolific_id (forcing prolific_id to be string if needed).\n",
    "df_creative['prolific_id'] = df_creative['prolific_id'].astype(str)\n",
    "df_demo['prolific_id'] = df_demo['prolific_id'].astype(str)\n",
    "df = pd.merge(df_creative, df_demo[['prolific_id', 'age_group']], on='prolific_id', how='left')\n",
    "\n",
    "# Filter out rows where age_group is \"I prefer not to answer\".\n",
    "df = df[df['age_group'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map creative_explanations_likeability responses to numeric values.\n",
    "# Expected responses: \"Strongly dislike\", \"Somewhat dislike\", \"Neither like nor dislike\", \"Somewhat like\", \"Strongly like\"\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "df[\"likeability_numeric\"] = df[\"creative_explanations_likeability\"].str.strip().map(likeability_mapping)\n",
    "\n",
    "# Map age_group to an ordinal numeric scale.\n",
    "# Expected age group options: \"18-25 years old\", \"26-35 years old\", \"36-50 years old\", \"Over 50 years old\"\n",
    "age_mapping = {\n",
    "    \"18-25 years old\": 1,\n",
    "    \"26-35 years old\": 2,\n",
    "    \"36-50 years old\": 3,\n",
    "    \"Over 50 years old\": 4\n",
    "}\n",
    "df[\"age_numeric\"] = df[\"age_group\"].map(age_mapping)\n",
    "\n",
    "# Drop rows with missing values in key measures.\n",
    "valid_df = df.dropna(subset=[\"likeability_numeric\", \"age_numeric\"])\n",
    "\n",
    "# Check if there are sufficient data points.\n",
    "if len(valid_df) < 2:\n",
    "    print(f\"Insufficient data to compute correlation (n = {len(valid_df)}).\")\n",
    "else:\n",
    "    # Compute Spearman correlation (suitable for ordinal data).\n",
    "    corr, p_val = spearmanr(valid_df[\"likeability_numeric\"], valid_df[\"age_numeric\"])\n",
    "    print(\"Correlation between creative explanations likeability and age group:\")\n",
    "    print(f\"  Spearman correlation: r = {corr:.3f}, p = {p_val:.3f}\")\n"
   ],
   "id": "85734105398bae09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between creative explanations likeability and age group:\n",
      "  Spearman correlation: r = -0.115, p = 0.250\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and level of education",
   "id": "6906116411fb82b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:01:17.212581Z",
     "start_time": "2025-03-15T17:01:17.187098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load the creative preferences file.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Load the demographics file that contains the education level.\n",
    "# Adjust the file name if necessary (e.g., \"m_creative_demographics.csv\").\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the two files on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'education_level']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where education_level is \"I prefer not to answer\".\n",
    "df = df[df['education_level'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map creative_explanations_likeability responses to numeric values.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "df['creative_explanations_likeability_numeric'] = df['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "\n",
    "# Map education_level to an ordinal numeric scale.\n",
    "education_mapping = {\n",
    "    \"Elementary education\": 1,\n",
    "    \"High school diploma or equivalent\": 2,\n",
    "    \"Bachelor's Degree\": 3,\n",
    "    \"Master's Degree\": 4,\n",
    "    \"Doctoral degree (PhD)\": 5\n",
    "}\n",
    "df['education_numeric'] = df['education_level'].str.strip().map(education_mapping)\n",
    "\n",
    "# Drop rows with missing values in the key columns.\n",
    "df = df.dropna(subset=['creative_explanations_likeability_numeric', 'education_numeric'])\n",
    "\n",
    "if len(df) < 2:\n",
    "    print(\"Insufficient data to compute correlation (n =\", len(df), \").\")\n",
    "else:\n",
    "    corr, p_val = pearsonr(df['creative_explanations_likeability_numeric'], df['education_numeric'])\n",
    "    print(\"Pearson correlation between creative explanations likeability and education level:\")\n",
    "    print(f\"  r = {corr:.3f}, p = {p_val:.3f}\")\n"
   ],
   "id": "be3832a800b0cb28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between creative explanations likeability and education level:\n",
      "  r = 0.139, p = 0.375\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and political orientation",
   "id": "ff71d5e6678c0fce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:02:51.813138Z",
     "start_time": "2025-03-15T17:02:51.783218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load creative preferences file\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Load demographics file (assumed to contain \"political_orientation\")\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the two datasets on prolific_id\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'political_orientation']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where political_orientation is \"I prefer not to answer\"\n",
    "df = df[df['political_orientation'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map creative_explanations_likeability to numeric values.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "df['creative_explanations_likeability_numeric'] = df['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "\n",
    "# Map political_orientation to an ordinal numeric scale.\n",
    "pol_mapping = {\n",
    "    \"Very Liberal\": 1,\n",
    "    \"Moderately Liberal\": 2,\n",
    "    \"Moderate\": 3,\n",
    "    \"Moderately Conservative\": 4,\n",
    "    \"Very Conservative\": 5\n",
    "}\n",
    "df['pol_numeric'] = df['political_orientation'].str.strip().map(pol_mapping)\n",
    "\n",
    "# Drop rows with missing values in key columns.\n",
    "df = df.dropna(subset=['creative_explanations_likeability_numeric', 'pol_numeric'])\n",
    "\n",
    "if len(df) < 2:\n",
    "    print(\"Insufficient data to compute correlation (n =\", len(df), \").\")\n",
    "else:\n",
    "    corr, p_val = pearsonr(df['creative_explanations_likeability_numeric'], df['pol_numeric'])\n",
    "    print(\"Pearson correlation between creative explanations likeability and political orientation:\")\n",
    "    print(f\"  r = {corr:.3f}, p = {p_val:.3f}\")\n"
   ],
   "id": "9e3164f0620c8e82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between creative explanations likeability and political orientation:\n",
      "  r = 0.004, p = 0.965\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and political engagement",
   "id": "cbe92467c7dbac41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:06:07.810855Z",
     "start_time": "2025-03-15T17:06:07.784369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load creative preferences file.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Load demographics file (assumed to contain \"engagement_with_political_content\").\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the two datasets on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'engagement_with_political_content']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where engagement_with_political_content is \"I prefer not to answer\".\n",
    "df = df[df['engagement_with_political_content'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map creative_explanations_likeability to numeric values.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "df['creative_explanations_likeability_numeric'] = df['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "\n",
    "# Map engagement_with_political_content to an ordinal numeric scale.\n",
    "engagement_mapping = {\n",
    "    \"Never\": 1,\n",
    "    \"Rarely\": 2,\n",
    "    \"Sometimes\": 3,\n",
    "    \"Often\": 4,\n",
    "    \"Very Frequently\": 5\n",
    "}\n",
    "df['engagement_numeric'] = df['engagement_with_political_content'].str.strip().map(engagement_mapping)\n",
    "\n",
    "# Drop rows with missing values in key columns.\n",
    "df = df.dropna(subset=['creative_explanations_likeability_numeric', 'engagement_numeric'])\n",
    "\n",
    "if len(df) < 2:\n",
    "    print(\"Insufficient data to compute correlation (n =\", len(df), \").\")\n",
    "else:\n",
    "    # Compute Pearson correlation.\n",
    "    corr, p_val = pearsonr(df['creative_explanations_likeability_numeric'], df['engagement_numeric'])\n",
    "    print(\"Pearson correlation between creative explanations likeability and political engagement:\")\n",
    "    print(f\"  r = {corr:.3f}, p = {p_val:.3f}\")"
   ],
   "id": "be5e7793ae52b0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between creative explanations likeability and political engagement:\n",
      "  r = -0.040, p = 0.694\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and meme familiarity",
   "id": "975ade029dec9d2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:07:19.606354Z",
     "start_time": "2025-03-15T17:07:19.584604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load the creative preferences file.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Load the corresponding demographics file (assumed to contain the meme_culture_familiarity column).\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the two datasets on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'meme_culture_familiarity']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where meme_culture_familiarity is \"I prefer not to answer\".\n",
    "df = df[df['meme_culture_familiarity'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map creative_explanations_likeability to numeric values.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "df['creative_explanations_likeability_numeric'] = df['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "\n",
    "# Map meme_culture_familiarity to a numeric ordinal scale.\n",
    "meme_culture_mapping = {\n",
    "    \"Not familiar at all (I rarely understand meme references)\": 1,\n",
    "    \"Slightly familiar (I understand basic, widely-known memes)\": 2,\n",
    "    \"Moderately familiar (I understand most popular memes and their variations)\": 3,\n",
    "    \"Very familiar (I understand complex meme references and their evolution)\": 4,\n",
    "    \"Extremely familiar (I actively follow meme trends and their cultural context)\": 5\n",
    "}\n",
    "df['meme_culture_numeric'] = df['meme_culture_familiarity'].str.strip().map(meme_culture_mapping)\n",
    "\n",
    "# Drop rows with missing values in key columns.\n",
    "df = df.dropna(subset=['creative_explanations_likeability_numeric', 'meme_culture_numeric'])\n",
    "\n",
    "if len(df) < 2:\n",
    "    print(\"Insufficient data to compute correlation (n =\", len(df), \").\")\n",
    "else:\n",
    "    corr, p_val = pearsonr(df['creative_explanations_likeability_numeric'], df['meme_culture_numeric'])\n",
    "    print(\"Pearson correlation between creative explanations likeability and meme culture familiarity:\")\n",
    "    print(f\"  r = {corr:.3f}, p = {p_val:.3f}\")\n"
   ],
   "id": "df58fefd757acbae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between creative explanations likeability and meme culture familiarity:\n",
      "  r = -0.105, p = 0.298\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and veracity discernment",
   "id": "c39b4641e2de0bac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:08:58.255482Z",
     "start_time": "2025-03-15T17:08:58.230213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Mapping for creative_explanations_likeability responses.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "\n",
    "# Compute veracity score from the claims file.\n",
    "# For the first 4 claim columns the correct answer is \"Fake News\"\n",
    "# and for the last 4 the correct answer is \"Real News\".\n",
    "def compute_veracity_score(df_claims):\n",
    "    # Exclude the \"prolific_id\" column.\n",
    "    cols = [col for col in df_claims.columns if col != \"prolific_id\"]\n",
    "    expected = [\"Fake News\"] * 4 + [\"Real News\"] * 4\n",
    "    scores = []\n",
    "    for idx, row in df_claims.iterrows():\n",
    "        score = 0\n",
    "        for col, exp in zip(cols, expected):\n",
    "            if isinstance(row[col], str) and row[col].strip() == exp:\n",
    "                score += 1\n",
    "        scores.append(score)\n",
    "    return pd.Series(scores, index=df_claims.index)\n",
    "\n",
    "def process_likeability_veracity_correlation(pref_filename, claims_filename, label):\n",
    "    # Load creative preferences file and veracity (claims) file.\n",
    "    df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / pref_filename, dtype={'prolific_id': str})\n",
    "    df_claims = pd.read_csv(get_working_dir() / 'data' / 'processed' / claims_filename, dtype={'prolific_id': str})\n",
    "    \n",
    "    # Map creative_explanations_likeability to numeric values.\n",
    "    df_pref['creative_explanations_likeability_numeric'] = df_pref['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "    \n",
    "    # Compute veracity score.\n",
    "    df_claims[\"veracity_score\"] = compute_veracity_score(df_claims)\n",
    "    \n",
    "    # Merge the two datasets on prolific_id.\n",
    "    df_merged = pd.merge(\n",
    "        df_pref[['prolific_id', 'creative_explanations_likeability_numeric']],\n",
    "        df_claims[['prolific_id', 'veracity_score']],\n",
    "        on=\"prolific_id\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Drop rows with missing values.\n",
    "    valid_df = df_merged.dropna(subset=[\"creative_explanations_likeability_numeric\", \"veracity_score\"])\n",
    "    \n",
    "    if len(valid_df) < 2:\n",
    "        print(f\"{label}: Insufficient data to compute correlation (n = {len(valid_df)}).\")\n",
    "    else:\n",
    "        corr, p_val = pearsonr(valid_df['creative_explanations_likeability_numeric'], valid_df['veracity_score'])\n",
    "        print(f\"{label}:\")\n",
    "        print(f\"  Pearson correlation between creative explanations likeability and veracity discernment: r = {corr:.3f}, p = {p_val:.3f}\")\n",
    "    print(\"-------\\n\")\n",
    "\n",
    "# Process for the creative explanations.\n",
    "# Adjust the file names as needed. Here we assume the creative preferences file is \"m_creative_preferences.csv\"\n",
    "# and the corresponding veracity discernment file is \"m_claims.csv\".\n",
    "process_likeability_veracity_correlation(\"m_creative_preferences.csv\", \"m_claims.csv\", \"Meme Creative Explanations\")\n"
   ],
   "id": "4c78f97bd5845240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meme Creative Explanations:\n",
      "  Pearson correlation between creative explanations likeability and veracity discernment: r = -0.176, p = 0.078\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce type and age group",
   "id": "2ab0d56970fc572c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:12:14.386323Z",
     "start_time": "2025-03-15T17:12:14.373724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load creative preferences and demographics files.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'age_group']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where age_group is \"I prefer not to answer\".\n",
    "df = df[df['age_group'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map age_group to an ordinal numeric scale.\n",
    "age_mapping = {\n",
    "    \"18-25 years old\": 1,\n",
    "    \"26-35 years old\": 2,\n",
    "    \"36-50 years old\": 3,\n",
    "    \"Over 50 years old\": 4\n",
    "}\n",
    "df['age_numeric'] = df['age_group'].map(age_mapping)\n",
    "\n",
    "# Drop rows with missing values in age_numeric.\n",
    "df = df.dropna(subset=['age_numeric'])\n",
    "\n",
    "# Compute the overall mean of age_numeric.\n",
    "overall_mean = df['age_numeric'].mean()\n",
    "\n",
    "# Compute total sum of squares.\n",
    "ss_total = np.sum((df['age_numeric'] - overall_mean)**2)\n",
    "\n",
    "# Compute between-group sum of squares.\n",
    "groups = df.groupby('most_effective_creative_explanation')\n",
    "ss_between = sum([len(group) * ((group['age_numeric'].mean() - overall_mean)**2) for name, group in groups])\n",
    "\n",
    "# Compute the correlation ratio (eta).\n",
    "eta = np.sqrt(ss_between / ss_total)\n",
    "\n",
    "# Also perform one-way ANOVA to obtain a p-value.\n",
    "group_values = [group['age_numeric'].values for name, group in groups]\n",
    "f_stat, p_val = f_oneway(*group_values)\n",
    "\n",
    "print(\"Association between 'most_effective_creative_explanation' and age group:\")\n",
    "print(f\"  Correlation ratio (Î·): {eta:.3f}\")\n",
    "print(f\"  One-way ANOVA F-statistic: {f_stat:.3f}, p-value: {p_val:.3f}\")\n"
   ],
   "id": "6d5672a07d82627a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association between 'most_effective_creative_explanation' and age group:\n",
      "  Correlation ratio (Î·): 0.202\n",
      "  One-way ANOVA F-statistic: 2.080, p-value: 0.130\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce type and level of education",
   "id": "559f98b92e94fbdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:14:15.807498Z",
     "start_time": "2025-03-15T17:14:15.772698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Load creative preferences and demographics files.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the two datasets on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo[['prolific_id', 'education_level']], on='prolific_id', how='inner')\n",
    "\n",
    "# Filter out rows where education_level is \"I prefer not to answer\".\n",
    "df = df[df['education_level'] != \"I prefer not to answer\"]\n",
    "\n",
    "# Map education levels to an ordinal numeric scale.\n",
    "education_mapping = {\n",
    "    \"Elementary education\": 1,\n",
    "    \"High school diploma or equivalent\": 2,\n",
    "    \"Bachelor's Degree\": 3,\n",
    "    \"Master's Degree\": 4,\n",
    "    \"Doctoral degree (PhD)\": 5\n",
    "}\n",
    "df['education_numeric'] = df['education_level'].str.strip().map(education_mapping)\n",
    "\n",
    "# Drop rows with missing education_numeric.\n",
    "df = df.dropna(subset=['education_numeric'])\n",
    "\n",
    "# Compute the overall mean of education_numeric.\n",
    "overall_mean = df['education_numeric'].mean()\n",
    "\n",
    "# Compute total sum of squares.\n",
    "ss_total = np.sum((df['education_numeric'] - overall_mean)**2)\n",
    "\n",
    "# Group by creative explanation type.\n",
    "groups = df.groupby('most_effective_creative_explanation')\n",
    "\n",
    "# Compute the between-group sum of squares.\n",
    "ss_between = sum([len(group) * ((group['education_numeric'].mean() - overall_mean)**2) \n",
    "                  for name, group in groups])\n",
    "\n",
    "# Compute the correlation ratio (eta).\n",
    "eta = np.sqrt(ss_between / ss_total)\n",
    "\n",
    "# Also perform one-way ANOVA to obtain a p-value.\n",
    "group_values = [group['education_numeric'].values for name, group in groups]\n",
    "f_stat, p_val = f_oneway(*group_values)\n",
    "\n",
    "print(\"Association between creative explanation type and education level:\")\n",
    "print(f\"  Correlation ratio (Î·): {eta:.3f}\")\n",
    "print(f\"  One-way ANOVA F-statistic: {f_stat:.3f}, p-value: {p_val:.3f}\")\n"
   ],
   "id": "d3e6905216c39f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association between creative explanation type and education level:\n",
      "  Correlation ratio (Î·): 0.224\n",
      "  One-way ANOVA F-statistic: 1.056, p-value: 0.357\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots for ce most effective type and demographic factors",
   "id": "56f687b1f4c1d681"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:12:22.015413Z",
     "start_time": "2025-04-14T14:12:21.504210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Define output directory and create it if it doesn't exist.\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load creative preferences and demographics files.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the datasets on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo, on='prolific_id', how='inner')\n",
    "\n",
    "# List of demographic variables to plot against \"most_effective_creative_explanation\".\n",
    "dem_vars = [\n",
    "    \"age_group\", \n",
    "    \"political_orientation\", \n",
    "    \"education_level\", \n",
    "    \"engagement_with_political_content\", \n",
    "    \"meme_culture_familiarity\"\n",
    "]\n",
    "\n",
    "# Loop over each demographic variable and create a bar plot.\n",
    "for var in dem_vars:\n",
    "    # Filter out rows where the demographic response is \"I prefer not to answer\".\n",
    "    df_filtered = df[df[var] != \"I prefer not to answer\"]\n",
    "    \n",
    "    # Create a crosstab (frequency table) of creative explanation type by the demographic variable.\n",
    "    ct = pd.crosstab(df_filtered[var], df_filtered[\"most_effective_creative_explanation\"])\n",
    "    \n",
    "    # Plot the frequency table as a grouped bar chart.\n",
    "    ax = ct.plot(kind='bar', figsize=(10,6), edgecolor='black')\n",
    "    plt.title(f\"Most Effective Creative Explanation by {var.replace('_', ' ').title()}\")\n",
    "    plt.xlabel(var.replace('_', ' ').title())\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Most Effective CE\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot.\n",
    "    plt.savefig(results_dir / f\"most_effective_creative_explanation_by_{var}.png\")\n",
    "    plt.close()\n"
   ],
   "id": "92a415169ee16597",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation between ce likeability and affect change",
   "id": "850b3658b616b44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:24:10.939913Z",
     "start_time": "2025-03-15T17:24:10.894819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Mapping for creative_explanations_likeability responses.\n",
    "likeability_mapping = {\n",
    "    \"Strongly dislike\": 1,\n",
    "    \"Somewhat dislike\": 2,\n",
    "    \"Neither like nor dislike\": 3,\n",
    "    \"Somewhat like\": 4,\n",
    "    \"Strongly like\": 5\n",
    "}\n",
    "\n",
    "# Mapping for affect responses.\n",
    "affect_mapping = {\n",
    "    \"Not at all\": 1,\n",
    "    \"Slightly\": 2,\n",
    "    \"Moderately\": 3,\n",
    "    \"Very\": 4,\n",
    "    \"Extremely\": 5\n",
    "}\n",
    "\n",
    "# Compute affect changes from the affect file.\n",
    "# Positive affect items: alert, inspired, determined, attentive, active.\n",
    "# Negative affect items: upset, hostile, ashamed, nervous, afraid.\n",
    "def compute_affect_changes(df_affect):\n",
    "    positive_items = [\"alert\", \"inspired\", \"determined\", \"attentive\", \"active\"]\n",
    "    negative_items = [\"upset\", \"hostile\", \"ashamed\", \"nervous\", \"afraid\"]\n",
    "    \n",
    "    # Map all affect responses using affect_mapping.\n",
    "    for col in df_affect.columns:\n",
    "        if df_affect[col].dtype == object:\n",
    "            df_affect[col] = df_affect[col].str.strip().map(affect_mapping)\n",
    "    \n",
    "    # Compute positive affect change: (post - pre) for each positive item.\n",
    "    pos_diffs = []\n",
    "    for item in positive_items:\n",
    "        pre_col = f\"pre_{item}\"\n",
    "        post_col = f\"post_{item}\"\n",
    "        if pre_col in df_affect.columns and post_col in df_affect.columns:\n",
    "            pos_diffs.append(df_affect[post_col] - df_affect[pre_col])\n",
    "    if pos_diffs:\n",
    "        pos_change = pd.concat(pos_diffs, axis=1).mean(axis=1)\n",
    "    else:\n",
    "        pos_change = pd.Series(np.nan, index=df_affect.index)\n",
    "    \n",
    "    # Compute negative affect change: (post - pre) for each negative item.\n",
    "    neg_diffs = []\n",
    "    for item in negative_items:\n",
    "        pre_col = f\"pre_{item}\"\n",
    "        post_col = f\"post_{item}\"\n",
    "        if pre_col in df_affect.columns and post_col in df_affect.columns:\n",
    "            neg_diffs.append(df_affect[post_col] - df_affect[pre_col])\n",
    "    if neg_diffs:\n",
    "        neg_change = pd.concat(neg_diffs, axis=1).mean(axis=1)\n",
    "    else:\n",
    "        neg_change = pd.Series(np.nan, index=df_affect.index)\n",
    "    \n",
    "    return pos_change, neg_change\n",
    "\n",
    "def process_likeability_affect_correlation(pref_filename, affect_filename, label):\n",
    "    # Load creative preferences file.\n",
    "    df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / pref_filename, dtype={'prolific_id': str})\n",
    "    # Map creative_explanations_likeability to numeric values.\n",
    "    df_pref['creative_explanations_likeability_numeric'] = df_pref['creative_explanations_likeability'].str.strip().map(likeability_mapping)\n",
    "    \n",
    "    # Load creative affect file.\n",
    "    df_affect = pd.read_csv(get_working_dir() / 'data' / 'processed' / affect_filename, dtype={'prolific_id': str})\n",
    "    pos_change, neg_change = compute_affect_changes(df_affect)\n",
    "    df_affect[\"positive_affect_change\"] = pos_change\n",
    "    df_affect[\"negative_affect_change\"] = neg_change\n",
    "    \n",
    "    # Merge the two datasets on prolific_id.\n",
    "    df_merged = pd.DataFrame({\n",
    "        'prolific_id': df_pref['prolific_id'],  # Use the valid prolific_ids\n",
    "        'creative_explanations_likeability_numeric': df_pref['creative_explanations_likeability_numeric'],\n",
    "        'positive_affect_change': df_affect['positive_affect_change'],\n",
    "        'negative_affect_change': df_affect['negative_affect_change']\n",
    "    })\n",
    "    \n",
    "    # Drop rows with missing values in key columns.\n",
    "    valid_df = df_merged.dropna(subset=['creative_explanations_likeability_numeric', 'positive_affect_change', 'negative_affect_change'])\n",
    "    \n",
    "    if len(valid_df) < 2:\n",
    "        print(f\"{label}: Insufficient data to compute correlation (n = {len(valid_df)}).\")\n",
    "    else:\n",
    "        corr_pos, p_pos = pearsonr(valid_df['creative_explanations_likeability_numeric'], valid_df['positive_affect_change'])\n",
    "        corr_neg, p_neg = pearsonr(valid_df['creative_explanations_likeability_numeric'], valid_df['negative_affect_change'])\n",
    "        print(f\"{label}:\")\n",
    "        print(f\"  Pearson correlation between CE likeability and positive affect change: r = {corr_pos:.3f}, p = {p_pos:.3f}\")\n",
    "        print(f\"  Pearson correlation between CE likeability and negative affect change: r = {corr_neg:.3f}, p = {p_neg:.3f}\")\n",
    "    print(\"-------\\n\")\n",
    "\n",
    "# Process for creative explanations.\n",
    "# Adjust file names if needed. Here we assume:\n",
    "# - Creative preferences are in \"m_creative_preferences.csv\"\n",
    "# - The corresponding creative affect file is \"m_creative_affect.csv\"\n",
    "process_likeability_affect_correlation(\"m_creative_preferences.csv\", \"m_affect.csv\", \"Creative Explanations\")\n"
   ],
   "id": "4a113da7239c3609",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creative Explanations:\n",
      "  Pearson correlation between CE likeability and positive affect change: r = -0.090, p = 0.368\n",
      "  Pearson correlation between CE likeability and negative affect change: r = 0.036, p = 0.721\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:15:43.070337Z",
     "start_time": "2025-04-14T14:15:43.024234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Define output directory (if later you want to save textual reports).\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load creative preferences and demographics files.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the datasets on prolific_id.\n",
    "df = pd.merge(df_pref, df_demo, on='prolific_id', how='inner')\n",
    "\n",
    "# List of demographic variables to analyze.\n",
    "dem_vars = [\n",
    "    \"age_group\", \n",
    "    \"political_orientation\", \n",
    "    \"education_level\", \n",
    "    \"engagement_with_political_content\", \n",
    "    \"meme_culture_familiarity\"\n",
    "]\n",
    "\n",
    "print(\"Most Effective Creative Explanation Type by Demographic Categories:\\n\")\n",
    "\n",
    "# Loop over each demographic variable.\n",
    "for var in dem_vars:\n",
    "    print(f\"=== {var.replace('_', ' ').title()} ===\")\n",
    "    # Filter out rows where the demographic response is \"I prefer not to answer\".\n",
    "    df_filtered = df[df[var] != \"I prefer not to answer\"]\n",
    "    \n",
    "    # Create a frequency table (crosstab) of creative explanation type by the demographic variable.\n",
    "    ct = pd.crosstab(df_filtered[var], df_filtered[\"most_effective_creative_explanation\"])\n",
    "    \n",
    "    # For each level of the demographic variable, find the most frequent creative explanation.\n",
    "    for level in ct.index:\n",
    "        # Find the creative explanation type with the highest count.\n",
    "        most_effective = ct.loc[level].idxmax()\n",
    "        count = ct.loc[level].max()\n",
    "        total = ct.loc[level].sum()\n",
    "        perc = 100 * count / total if total > 0 else 0\n",
    "        print(f\"  {level}: {most_effective} ({count} out of {total} responses, {perc:.1f}%)\")\n",
    "    print()  # newline for spacing between demographics\n"
   ],
   "id": "17770a12e5ecd551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Effective Creative Explanation Type by Demographic Categories:\n",
      "\n",
      "=== Age Group ===\n",
      "  18-25 years old: The meme (6 out of 8 responses, 75.0%)\n",
      "  26-35 years old: The meme (21 out of 37 responses, 56.8%)\n",
      "  36-50 years old: The meme (23 out of 31 responses, 74.2%)\n",
      "  Over 50 years old: The poem (11 out of 25 responses, 44.0%)\n",
      "\n",
      "=== Political Orientation ===\n",
      "  Moderate: The meme (17 out of 24 responses, 70.8%)\n",
      "  Moderately Conservative: The meme (14 out of 28 responses, 50.0%)\n",
      "  Moderately Liberal: The meme (13 out of 23 responses, 56.5%)\n",
      "  Very Conservative: The meme (3 out of 7 responses, 42.9%)\n",
      "  Very Liberal: The meme (12 out of 19 responses, 63.2%)\n",
      "\n",
      "=== Education Level ===\n",
      "  Bachelor's degree: The meme (24 out of 40 responses, 60.0%)\n",
      "  Doctoral degree (PhD): The meme (4 out of 7 responses, 57.1%)\n",
      "  High school diploma or equivalent: The meme (22 out of 36 responses, 61.1%)\n",
      "  Master's degree: The meme (7 out of 16 responses, 43.8%)\n",
      "\n",
      "=== Engagement With Political Content ===\n",
      "  Never: The meme (4 out of 6 responses, 66.7%)\n",
      "  Often: The meme (23 out of 33 responses, 69.7%)\n",
      "  Rarely: The meme (9 out of 15 responses, 60.0%)\n",
      "  Sometimes: The meme (17 out of 32 responses, 53.1%)\n",
      "  Very Frequently: The meme (6 out of 15 responses, 40.0%)\n",
      "\n",
      "=== Meme Culture Familiarity ===\n",
      "  Extremely familiar (I actively follow meme trends and their cultural context): The meme (20 out of 38 responses, 52.6%)\n",
      "  Moderately familiar (I understand most popular memes and their variations): The meme (14 out of 22 responses, 63.6%)\n",
      "  Slightly familiar (I understand basic, widely-known memes): The poem (1 out of 1 responses, 100.0%)\n",
      "  Very familiar (I understand complex meme references and their evolution): The meme (25 out of 40 responses, 62.5%)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:17:57.936915Z",
     "start_time": "2025-04-14T14:17:57.895641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def get_working_dir():\n",
    "    return Path.cwd()\n",
    "\n",
    "# Define an output directory (if needed for future uses).\n",
    "results_dir = get_working_dir() / 'plots' / 'creative_explanations'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load creative preferences and demographics files.\n",
    "df_pref = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_creative_preferences.csv', dtype={'prolific_id': str})\n",
    "df_demo = pd.read_csv(get_working_dir() / 'data' / 'processed' / 'm_demographics.csv', dtype={'prolific_id': str})\n",
    "\n",
    "# Merge the datasets on prolific_id. (Demographics are merged even if not used in this analysis.)\n",
    "df = pd.merge(df_pref, df_demo, on='prolific_id', how='inner')\n",
    "\n",
    "# Count the frequency of each creative explanation option.\n",
    "creative_counts = df['most_effective_creative_explanation'].value_counts()\n",
    "total = creative_counts.sum()\n",
    "\n",
    "print(\"Frequency counts for each creative explanation option:\")\n",
    "for option, count in creative_counts.items():\n",
    "    percentage = 100 * count / total\n",
    "    print(f\"  {option}: {count} responses ({percentage:.1f}%)\")\n"
   ],
   "id": "70f1150ae0ae7a5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts for each creative explanation option:\n",
      "  The meme: 59 responses (58.4%)\n",
      "  The poem: 25 responses (24.8%)\n",
      "  The joke: 17 responses (16.8%)\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
