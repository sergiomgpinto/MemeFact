{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T14:51:58.213863Z",
     "start_time": "2025-04-16T14:51:58.172777Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths (assuming the notebooks and data directories are siblings)\n",
    "input_file_path = \"../data/x_bot_data.csv\"\n",
    "output_file_path = \"../data/x_bot_data_phase1.csv\"\n",
    "\n",
    "# Read the CSV file with semicolon delimiter\n",
    "df = pd.read_csv(input_file_path, sep=\";\")\n",
    "\n",
    "# Replace the substring \"pinto_serg4991\" with \"Meme__Fact\" in the URL columns\n",
    "df[\"meme_post_url\"] = df[\"meme_post_url\"].str.replace(\"pinto_serg4991\", \"Meme__Fact\", regex=False)\n",
    "df[\"disclaimer_url\"] = df[\"disclaimer_url\"].str.replace(\"pinto_serg4991\", \"Meme__Fact\", regex=False)\n",
    "\n",
    "# Define columns to drop (including fact_check_verdict and additional unwanted columns)\n",
    "cols_to_drop = [\n",
    "    \"misinformation_topic_tags\", \"meme_explains_verdict\", \"meme_humor_rating\", \"meme_relevance_rating\",\n",
    "    \"reply_texts_disclaimer_post\", \"reply_texts_meme_post\",\n",
    "    \"reposted_by_user\", \"liked_by_user\", \"replied_by_user\", \"blocked_by_user\", \"followed_by_user\",\n",
    "    \"engagement_growth_rate_24h\", \"engagement_growth_rate_7d\", \"engagement_growth_rate_1m\", \"engagement_growth_rate_3m\",\n",
    "    \"views_7d\", \"likes_7d\", \"reposts_7d\", \"replies_7d\", \"quote_tweets_7d\",\n",
    "    \"views_1m\", \"likes_1m\", \"reposts_1m\", \"replies_1m\", \"quote_tweets_1m\",\n",
    "    \"views_3m\", \"likes_3m\", \"reposts_3m\", \"replies_3m\", \"quote_tweets_3m\",\n",
    "    \"views_24h\", \"likes_24h\", \"reposts_24h\", \"replies_24h\", \"quote_tweets_24h\",\n",
    "    \"fact_check_verdict\", \"error\"\n",
    "]\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename the 1-hour metric columns to temporary names for later processing.\n",
    "rename_dict = {\n",
    "    \"views_1h\": \"views\",\n",
    "    \"likes_1h\": \"likes\",\n",
    "    \"reposts_1h\": \"reposts\",\n",
    "    \"replies_1h\": \"replies\",\n",
    "    \"quote_tweets_1h\": \"quote_tweets\"\n",
    "}\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Group by 'fact_check_timestamp' to merge duplicate rows.\n",
    "# For numeric columns, sum their values; otherwise, take the first occurrence.\n",
    "numeric_cols = [\"views\", \"likes\", \"reposts\", \"replies\", \"quote_tweets\"]\n",
    "agg_methods = {\n",
    "    col: (\"sum\" if col in numeric_cols else \"first\")\n",
    "    for col in df.columns if col != \"fact_check_timestamp\"\n",
    "}\n",
    "df_grouped = df.groupby(\"fact_check_timestamp\", as_index=False).agg(agg_methods)\n",
    "\n",
    "# Now drop the columns: 'reposts', 'replies', 'quote_tweets'\n",
    "df_grouped.drop(columns=[\"reposts\", \"replies\", \"quote_tweets\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename the metric columns for the meme post.\n",
    "df_grouped.rename(columns={\"views\": \"views_meme_post\", \"likes\": \"likes_meme_post\"}, inplace=True)\n",
    "\n",
    "# Insert the new columns for disclaimer posts right after the meme post columns.\n",
    "# We will initialize these with missing values (pd.NA)\n",
    "views_index = df_grouped.columns.get_loc(\"views_meme_post\")\n",
    "df_grouped.insert(views_index + 1, \"views_disclaimer_post\", pd.NA)\n",
    "\n",
    "likes_index = df_grouped.columns.get_loc(\"likes_meme_post\")\n",
    "df_grouped.insert(likes_index + 1, \"likes_disclaimer_post\", pd.NA)\n",
    "\n",
    "# Sort the DataFrame by fact_check_timestamp in ascending order and reset the index\n",
    "df_grouped.sort_values(by=\"fact_check_timestamp\", inplace=True)\n",
    "df_grouped.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the processed DataFrame to the new CSV file in the data directory\n",
    "df_grouped.to_csv(output_file_path, index=False)\n",
    "print(f\"Processed data has been saved to {output_file_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data has been saved to ../data/x_bot_data_phase1.csv\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
